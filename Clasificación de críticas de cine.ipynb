{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Autor: Javier Garrucho Fernández"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Críticas de cine en IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos serán críticas de películas en la web IMDB (Internet Movie Database). Son críticas que ya vienen con la etiqueta \"pos\" o \"neg\", de acuerdo a la puntuación que acompaña a la crítica (positiva, 7 o más; negativa 4 o menos). El objetivo es ser capaz de declarar como positiva o negativa una crítica (por supuesto, sin saber la puntuación que la acompaña)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"data/aclImdb/train/\",encoding='utf-8')\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "\n",
    "reviews_test = load_files(\"data/aclImdb/test/\",encoding='utf-8')\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitamos algunas marcas en HTML, para \"limpiar\" los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(\"<br />\", \" \") for doc in text_train]\n",
    "text_test = [doc.replace(\"<br />\", \" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder aplicar los clasificadores de Scikit Learn, hemos de vectorizar los textos. En scikitlearn se pueden elegir varias formas de vectorizar:\n",
    "\n",
    "* **CountVectorizer**, modo binario (sólo se anota si un término ocurre o no)\n",
    "* **CountVectorizer**, contando ocurrencias\n",
    "* **TfIdfVectorizer**, vectorizando con TfIdf\n",
    "\n",
    "El uso de estos vectorizadores se puede comprender a partir de lo visto en el tema de Procesamiento de Lenguaje Natural, y del manual de Scikit Learn. En particular **es importante el uso de los parámetros stop_words y min_df** para simplificar a vectorización. Una vez entendido y explorado su uso, elegir la mejor combinación de vectorizador y de clasificador, para este conjunto de datos. \n",
    "\n",
    "También mostrar la predicción que se realiza sobre algunas críticas concretas del conjunto de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos viendo el tamaño del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "print(len(text_train),len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay un total de 50000 reviews, y se utiliza la mitad para entrenamiento y la otra mitad para test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las stop words en este caso utilizaré el conjunto que proporciona scikitlearn para el inglés, aunque podría ser interesante hacer uno más específico para este problema en concreto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el vectorizador y vectorizamos los textos del conjunto de entrenamiento para obtener el vocabulario, lo guardamos en X_train_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(min_df=1, stop_words=\"english\")\n",
    "X_train_counts = count_vect.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar que un texto por ser más grande y por tanto aparezca más veces una palabra que en uno más pequeño utilizamos la frecuencia del término, en vez de simplemente las veces que este aparece.\n",
    "\n",
    "Para ello creamos un transformador a vector de pesos y se prepara para que pueda transformar otros vectores de ocurrencias en vectores de pesos, guardamos los vectores referentes al conjunto de entrenamiento en X_train_tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vectorizamos los textos del conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts = count_vect.transform(text_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tanto los textos de test como de entrenamiento están representados correctamente en forma de vectores, ya podemos entrenar nuestro modelo y ver sus resultados, vamos a probar primero con los dos métodos vistos en clase para clasificación de texto, knn y Naive Bayes Multinomial.\n",
    "\n",
    "Primero con **KNN**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_text = KNeighborsClassifier(n_neighbors=3).fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto sobre entrenamiento: 0.891\n",
      "Tasa de acierto sobre test: 0.630\n",
      "Matriz de confusión:\n",
      "[[8161 4339]\n",
      " [4915 7585]]\n"
     ]
    }
   ],
   "source": [
    "pred_train = neigh_text.predict(X_train_tfidf)\n",
    "pred_test = neigh_text.predict(X_test_tfidf)\n",
    "print(\"Tasa de acierto sobre entrenamiento: {:.3f}\".format(accuracy_score(y_train, pred_train)))\n",
    "print(\"Tasa de acierto sobre test: {:.3f}\".format(accuracy_score(y_test, pred_test)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion_matrix(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN consigue relativamente buenos resultado en el conjunto de entrenamiento, sin embargo sobre el conjunto de test no clasifica demasiado bien.\n",
    "\n",
    "Provemos ahora con **Naive Bayes Multinomial**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_text = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto sobre entrenamiento: 0.915\n",
      "Tasa de acierto sobre test: 0.830\n",
      "Matriz de confusión:\n",
      "[[10961  1539]\n",
      " [ 2720  9780]]\n"
     ]
    }
   ],
   "source": [
    "pred_train = mnb_text.predict(X_train_tfidf)\n",
    "pred_test = mnb_text.predict(X_test_tfidf)\n",
    "print(\"Tasa de acierto sobre entrenamiento: {:.3f}\".format(accuracy_score(y_train, pred_train)))\n",
    "print(\"Tasa de acierto sobre test: {:.3f}\".format(accuracy_score(y_test, pred_test)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion_matrix(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método clasifica bastante mejor, aunque sigue teniendo un error grande.\n",
    "\n",
    "Para determinar el mejor valor para min_df vamos a utilizar de nuevo **Grid-Search**, para hacerlo más compacto usaremos un **pipeline**, que reducirá los tres pasos (vectorización, transformación y entrenamiento) en una función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIUDADO Esta función puede tardar varios minutos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score=0\n",
    "for min_df in [0.1, 0.2, 0.3, 1]:#Probamos estos valores para min_df (min_df=1 es por defecto)\n",
    "        gs_txt_clf = text_clf = Pipeline([\n",
    "         ('vect', CountVectorizer(min_df=min_df, stop_words=\"english\")),\n",
    "         ('tfidf', TfidfTransformer()),\n",
    "         ('clf', MultinomialNB())\n",
    "        ])\n",
    "        # Realiza validación cruzada \n",
    "        scores = cross_val_score(gs_txt_clf, text_train, y_train, cv=5)\n",
    "        # calcula el resultado medio de la validación cruzada\n",
    "        score = np.mean(scores)\n",
    "        # nos vamos quedando con la mejor combinación\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_min_df = min_df\n",
    "            \n",
    "# Volvemos a entrenar el modelo con la mejor combinación encontrada, sobre entrenamieno+validación  \n",
    "# y evaluamos el rendimiento sobre el conjunto de prueba \n",
    "gs_txt_clf = text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer(min_df=best_min_df, stop_words=\"english\")),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', MultinomialNB())\n",
    "]).fit(text_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado sobre validación: 0.86548\n",
      "Mejor min_df:  1\n",
      "Evaluación sobre el conjunto de test: 0.82964\n",
      "Matriz de confusión:\n",
      "[[10961  1539]\n",
      " [ 2720  9780]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor resultado sobre validación: {:.5f}\".format(best_score))\n",
    "print(\"Mejor min_df: \", best_min_df)\n",
    "pred_test = gs_txt_clf.predict(text_test)\n",
    "test_score = accuracy_score(y_test, pred_test)\n",
    "print(\"Evaluación sobre el conjunto de test: {:.5f}\".format(test_score))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion_matrix(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor valor obtenido para min_df ha sido 1. Con un score de 0.865 sobre el conjunto de validación y un porcentaje de aciertos del 83% sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con **regresión logística:**\n",
    "\n",
    "De nuevo haciendo grid-dearch con validación cruzada para determinar ahora el valor para C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIUDADO Esta función puede tardar varios minutos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score=0\n",
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    gs_txt_clf = text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer(min_df=1, stop_words=\"english\")),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegression(max_iter=1000, C=C, penalty=\"l2\"))\n",
    "    ])\n",
    "    # Realiza validación cruzada \n",
    "    scores = cross_val_score(gs_txt_clf, text_train, y_train, cv=5)\n",
    "    # calcula el resultado medio de la validación cruzada\n",
    "    score = np.mean(scores)\n",
    "    # nos vamos quedando con la mejor combinación\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = {'C': C}\n",
    "        \n",
    "gs_txt_clf = text_clf = Pipeline([\n",
    " ('vect', CountVectorizer(min_df=1, stop_words=\"english\")),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('clf', LogisticRegression(max_iter=1000,**best_parameters, penalty=\"l2\"))\n",
    "]).fit(text_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado sobre validación: 0.89024\n",
      "Mejor combinación de valores:  {'C': 10}\n",
      "Evaluación sobre el conjunto de test: 0.87116\n",
      "Matriz de confusión:\n",
      "[[11012  1488]\n",
      " [ 1733 10767]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor resultado sobre validación: {:.5f}\".format(best_score))\n",
    "print(\"Mejor combinación de valores: \", best_parameters)\n",
    "pred_test = gs_txt_clf.predict(text_test)\n",
    "test_score = accuracy_score(y_test, pred_test)\n",
    "print(\"Evaluación sobre el conjunto de test: {:.5f}\".format(test_score))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion_matrix(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de todos los métodos probados regresión logística con C=10 es con el que mejor puntuación he obtenido, con un 89% de acierto sobre el conjunto de validación y un 87% sobre el conjunto de test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
